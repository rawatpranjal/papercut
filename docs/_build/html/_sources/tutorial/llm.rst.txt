LLM Features
============

AI-powered analysis for papers and books.

Setup
-----

Install with LLM support:

.. code-block:: bash

   pip install papercutter[llm]

Set your API key:

.. code-block:: bash

   export OPENAI_API_KEY=sk-...
   # or
   export ANTHROPIC_API_KEY=sk-...

Summarizing Papers
------------------

Generate summaries with customizable focus and length:

.. code-block:: bash

   # Default summary
   papercutter summarize paper.pdf

   # Focus on specific aspects
   papercutter summarize paper.pdf --focus methods
   papercutter summarize paper.pdf --focus results
   papercutter summarize paper.pdf --focus contributions

   # Adjust length
   papercutter summarize paper.pdf --length short
   papercutter summarize paper.pdf --length long

Reports
-------

Generate structured reports for different audiences:

.. code-block:: bash

   # Reading group presentation
   papercutter report paper.pdf --template reading-group

   # Referee review
   papercutter report paper.pdf --template referee

   # Meta-analysis notes
   papercutter report paper.pdf --template meta

   # Executive summary
   papercutter report paper.pdf --template executive

Study Aids
----------

Generate study materials from book chapters:

.. code-block:: bash

   # Chapter summary
   papercutter study book.pdf --chapter 5

   # Key concepts
   papercutter study book.pdf --chapter 5 --mode concepts

   # Practice quiz
   papercutter study book.pdf --chapter 5 --mode quiz

   # Flashcards
   papercutter study book.pdf --chapter 5 --mode flashcards

Tips
----

1. **Token limits**: Long papers may be truncated. Use ``--focus`` to target specific sections.

2. **Model selection**: Configure via ``PAPERCUTTER_MODEL`` environment variable.

3. **Cost awareness**: LLM calls consume tokens. Track usage for budgeting.

.. seealso::

   :doc:`python/workflows` for Python API examples including batch processing, complete pipelines, and model configuration.
